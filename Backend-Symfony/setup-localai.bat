@echo off
echo ========================================
echo    AGORA - LocalAI Installation Script
echo ========================================
echo.

:: Verificar si Docker estÃ¡ instalado
docker --version >nul 2>&1
if errorlevel 1 (
    echo âŒ ERROR: Docker no estÃ¡ instalado
    echo ğŸ“¥ Descarga Docker Desktop desde: https://docker.com/products/docker-desktop
    pause
    exit /b 1
)

echo âœ… Docker detectado

:: Crear directorio para modelos de LocalAI
if not exist "localai-models" (
    mkdir localai-models
    echo ğŸ“ Directorio localai-models creado
)

echo.
echo ğŸ§  INICIANDO LOCALAI CON LLAMA 2...
echo ğŸ“Š Esto descargarÃ¡ ~4GB la primera vez
echo â±ï¸  Puede tomar 10-15 minutos
echo.

:: Ejecutar LocalAI con Docker
docker run -d ^
  --name agora-localai ^
  -p 8080:8080 ^
  -v "%cd%\localai-models:/models" ^
  -e MODELS_PATH=/models ^
  -e THREADS=4 ^
  -e DEBUG=true ^
  localai/localai:latest

if errorlevel 0 (
    echo.
    echo âœ… LocalAI iniciado correctamente
    echo ğŸŒ Accesible en: http://localhost:8080
    echo ğŸ“Š Panel de control: http://localhost:8080/browse
    echo.
    echo ğŸ”„ Descargando modelo Llama-2-7b-chat...
    
    :: Descargar modelo Llama 2 optimizado
    curl -L "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.q4_0.bin" -o "localai-models/llama-2-7b-chat.q4_0.bin"
    
    if errorlevel 0 (
        echo âœ… Modelo Llama-2 descargado
        echo ğŸ¯ LocalAI listo para usar
    ) else (
        echo âš ï¸  Error descargando modelo, pero LocalAI funciona
        echo ğŸ“ Puedes descargar modelos desde el panel web
    )
    
    echo.
    echo ğŸ”¥ LOCALAI CONFIGURADO COMPLETAMENTE
    echo ğŸ“‹ PrÃ³ximo paso: Conectar con Symfony backend
    pause
) else (
    echo âŒ Error iniciando LocalAI
    echo ğŸ’¡ Verifica que Docker estÃ© ejecutÃ¡ndose
    pause
    exit /b 1
)