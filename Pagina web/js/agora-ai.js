// ===== √ÅGORA AI SERVICE =====
// Integraci√≥n con LocalAI para bots inteligentes

class AgoraAIService {
    constructor() {
        this.baseURL = 'http://localhost/Backend-Symfony/public/api/ai';
        this.isLocalAIAvailable = false;
        this.currentModel = 'llama-2-7b-chat';
        this.conversationHistory = new Map(); // Bot ID -> Historial
        
        this.init();
    }

    async init() {
        console.log('üß† Inicializando √Ågora AI Service...');
        await this.checkAIStatus();
    }

    // ===== STATUS Y CONFIGURACI√ìN =====
    async checkAIStatus() {
        try {
            const response = await fetch(`${this.baseURL}/status`);
            const result = await response.json();
            
            if (result.success) {
                this.isLocalAIAvailable = result.data.localai_status.is_available;
                console.log('‚úÖ LocalAI Status:', result.data);
                return result.data;
            } else {
                console.warn('‚ö†Ô∏è AI Status check failed:', result.error);
                this.isLocalAIAvailable = false;
                return null;
            }
        } catch (error) {
            console.error('‚ùå Error checking AI status:', error);
            this.isLocalAIAvailable = false;
            return null;
        }
    }

    async getAvailableModels() {
        try {
            const response = await fetch(`${this.baseURL}/models`);
            const result = await response.json();
            
            if (result.success) {
                return result.data;
            }
            
            return { models: [], recommendations: {} };
        } catch (error) {
            console.error('‚ùå Error getting models:', error);
            return { models: [], recommendations: {} };
        }
    }

    async setModel(modelName) {
        try {
            const response = await fetch(`${this.baseURL}/model`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ model: modelName })
            });
            
            const result = await response.json();
            
            if (result.success) {
                this.currentModel = modelName;
                console.log(`‚úÖ Modelo cambiado a: ${modelName}`);
                return true;
            }
            
            console.error('‚ùå Error setting model:', result.error);
            return false;
        } catch (error) {
            console.error('‚ùå Error setting model:', error);
            return false;
        }
    }

    // ===== CHAT CON BOTS IA =====
    async chatWithBot(botData, userMessage, userName = 'Usuario') {
        try {
            // Preparar historial de conversaci√≥n
            const botId = botData.id;
            if (!this.conversationHistory.has(botId)) {
                this.conversationHistory.set(botId, []);
            }
            
            const history = this.conversationHistory.get(botId);
            
            // A√±adir mensaje del usuario al historial
            history.push({
                role: 'user',
                content: userMessage,
                timestamp: Date.now()
            });

            // Preparar datos para el backend
            const requestData = {
                user_message: userMessage,
                user_name: userName,
                bot_id: botData.id,
                bot_name: botData.name,
                bot_personality: botData.personality || 'Eres un asistente √∫til y amigable',
                bot_type: botData.type || 'general',
                language: 'es',
                tone: botData.tone || 'amigable',
                history: history.slice(-10) // Solo √∫ltimos 10 mensajes
            };

            console.log(`ü§ñ Enviando mensaje a ${botData.name}:`, userMessage);

            const response = await fetch(`${this.baseURL}/chat`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestData)
            });

            const result = await response.json();

            if (result.success) {
                const botResponse = result.data.bot_response;
                
                // A√±adir respuesta del bot al historial
                history.push({
                    role: 'assistant',
                    content: botResponse,
                    timestamp: Date.now()
                });

                // Mantener solo √∫ltimos 20 mensajes por performance
                if (history.length > 20) {
                    this.conversationHistory.set(botId, history.slice(-20));
                }

                console.log(`‚úÖ Respuesta de ${botData.name}:`, botResponse);
                
                return {
                    success: true,
                    response: botResponse,
                    metadata: {
                        bot_name: result.data.bot_name,
                        message_id: result.data.message_id,
                        timestamp: result.data.timestamp,
                        ai_powered: result.data.ai_powered,
                        model_used: result.data.model_used,
                        response_time: result.data.response_time
                    }
                };
                
            } else {
                console.error('‚ùå Error en chat con bot:', result.error);
                
                // Fallback a respuesta mock
                return this.getMockResponse(botData, userMessage);
            }

        } catch (error) {
            console.error('‚ùå Error chatting with bot:', error);
            
            // Fallback a respuesta mock
            return this.getMockResponse(botData, userMessage);
        }
    }

    // ===== FALLBACK RESPONSES =====
    getMockResponse(botData, userMessage) {
        const responses = {
            'hola': `¬°Hola! Soy ${botData.name}. Estoy funcionando en modo offline, pero a√∫n puedo ayudarte.`,
            'gracias': '¬°De nada! Siempre es un placer ayudar.',
            'ayuda': `Soy ${botData.name}, un bot de √Ågora. Ahora mismo estoy en modo offline, pero cuando LocalAI est√© activo ser√© mucho m√°s inteligente.`,
            'que eres': `Soy ${botData.name}, ${botData.personality || 'un bot amigable'}`,
            'default': `Interesante. Soy ${botData.name} y aunque LocalAI no est√° disponible ahora, ¬°puedo conversar contigo!`
        };

        const message = userMessage.toLowerCase();
        let response = responses['default'];

        for (const [keyword, resp] of Object.entries(responses)) {
            if (message.includes(keyword)) {
                response = resp;
                break;
            }
        }

        return {
            success: true,
            response: response,
            metadata: {
                bot_name: botData.name,
                message_id: 'mock_' + Date.now(),
                timestamp: Date.now(),
                ai_powered: false,
                model_used: 'Mock Response',
                response_time: 0.1
            }
        };
    }

    // ===== UTILIDADES =====
    getConversationHistory(botId) {
        return this.conversationHistory.get(botId) || [];
    }

    clearConversationHistory(botId) {
        if (botId) {
            this.conversationHistory.delete(botId);
        } else {
            this.conversationHistory.clear();
        }
    }

    isAIAvailable() {
        return this.isLocalAIAvailable;
    }

    getCurrentModel() {
        return this.currentModel;
    }

    // ===== INFORMACI√ìN PARA UI =====
    getAIStatusInfo() {
        return {
            available: this.isLocalAIAvailable,
            model: this.currentModel,
            conversations: this.conversationHistory.size,
            status: this.isLocalAIAvailable ? 'üü¢ LocalAI Activo' : 'üî¥ LocalAI Offline'
        };
    }
}

// Instancia global
window.agoraAI = new AgoraAIService();

console.log('üß† √Ågora AI Service cargado');
console.log('üìä Estado inicial:', window.agoraAI.getAIStatusInfo());