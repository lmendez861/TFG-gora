# üß† **√ÅGORA AI - LocalAI Integration Guide**

## üéØ **¬øQu√© hemos implementado?**

### ‚úÖ **BACKEND SYMFONY**
- **LocalAIService.php**: Servicio completo para comunicarse con LocalAI
- **AIBotController.php**: API endpoints para chat con IA
- **Modelos configurados**: Llama-2-7B-Chat + Code-Llama-7B
- **Fallback inteligente**: Si LocalAI no est√° disponible, usa respuestas mock

### ‚úÖ **FRONTEND JAVASCRIPT**
- **agora-ai.js**: Servicio frontend para integraci√≥n con LocalAI
- **Panel de control IA**: Interfaz completa para gestionar IA
- **Chat real-time**: Mensajes con IA verdadera
- **Indicadores visuales**: Estado de conexi√≥n, modelo activo, estad√≠sticas

### ‚úÖ **INFRAESTRUCTURA**
- **Docker setup**: LocalAI server con Docker
- **Modelos optimizados**: Configuraciones YAML para mejor rendimiento  
- **Scripts automatizados**: Instalaci√≥n completa en un comando

---

## üöÄ **INSTALACI√ìN R√ÅPIDA**

### **M√©todo 1: Script Autom√°tico (RECOMENDADO)**
```bash
cd "C:\Users\lourd\Desktop\TFG - Agora\Backend-Symfony"
.\install-agora-ai.bat
```

**¬°Eso es todo!** El script instala y configura todo autom√°ticamente.

### **M√©todo 2: Manual**
```bash
# 1. Instalar Docker Desktop
# Descargar desde: https://docker.com/products/docker-desktop

# 2. Clonar LocalAI
docker pull localai/localai:latest

# 3. Iniciar servidor
docker run -d --name agora-localai -p 8080:8080 localai/localai:latest

# 4. Verificar funcionamiento
curl http://localhost:8080/health
```

---

## üéÆ **C√ìMO USAR LA IA EN √ÅGORA**

### **1. Verificar Estado de IA**
1. Abrir `agora-platform-demo.html`
2. Buscar el indicador **"IA"** en el header (esquina superior derecha)
3. **üü¢ Verde** = IA activa | **üî¥ Rojo** = IA desconectada

### **2. Panel de Control IA**
- **Clic en indicador IA** ‚Üí Se abre panel lateral
- **Estado General**: Conexi√≥n, modelo activo, conversaciones
- **Modelos Disponibles**: Cambiar entre Llama-2, Code-Llama, etc.
- **Acciones**: Verificar conexi√≥n, limpiar historial, ver logs

### **3. Chatear con IA Real**
1. **Crear bot personal** (si no tienes uno)
2. **Escribir mensaje** en el chat
3. **El bot responde** usando LocalAI real
4. **Indicadores especiales**:
   - üß† = IA real activa
   - ü§ñ = Respuesta mock/fallback
   - Tiempo de respuesta mostrado

---

## üîß **CONFIGURACI√ìN AVANZADA**

### **Modelos Disponibles**
```yaml
# Llama-2-7B-Chat (General)
- Tama√±o: ~4GB
- Uso: Conversaciones generales, asistencia
- Velocidad: R√°pida
- Calidad: Alta

# Code-Llama-7B (Programaci√≥n) 
- Tama√±o: ~4GB
- Uso: C√≥digo, debugging, explicaciones t√©cnicas
- Velocidad: Media
- Calidad: Excelente para c√≥digo

# GPT4All-J (Ligero)
- Tama√±o: ~1GB  
- Uso: Pruebas r√°pidas
- Velocidad: Muy r√°pida
- Calidad: B√°sica
```

### **Cambiar Modelo Activo**
1. **Panel IA** ‚Üí **Modelos Disponibles**
2. **Clic en modelo deseado**
3. **Confirmaci√≥n autom√°tica**
4. **Todos los nuevos chats** usan el nuevo modelo

### **Personalizar Bots**
```javascript
// En el modal de crear bot:
- Personalidad: "Eres un experto en [tema]"
- Tipo: General / Reglas / IA  
- Tono: Formal / Amigable / T√©cnico
- Comandos: Palabras clave especiales
```

---

## üìä **ARQUITECTURA T√âCNICA**

### **Flujo de Datos**
```
Usuario escribe mensaje
    ‚Üì
Frontend (agora-ai.js)
    ‚Üì  
API Symfony (AIBotController)
    ‚Üì
LocalAIService.php
    ‚Üì
LocalAI Server (Docker)
    ‚Üì
Modelo IA (Llama-2)
    ‚Üì
Respuesta procesada
    ‚Üì
Mostrar en chat con metadatos
```

### **APIs Disponibles**
```php
POST /api/ai/chat
- Enviar mensaje a bot IA
- Body: { user_message, bot_id, bot_name, etc. }
- Response: { bot_response, metadata }

GET /api/ai/status  
- Estado del sistema IA
- Response: { localai_status, models, recommendations }

GET /api/ai/models
- Modelos disponibles  
- Response: { models[], recommendations }

POST /api/ai/model
- Cambiar modelo activo
- Body: { model: "llama-2-7b-chat" }
```

### **Fallbacks Inteligentes**
1. **IA disponible** ‚Üí Respuesta real de LocalAI
2. **IA no disponible** ‚Üí Respuesta mock inteligente  
3. **Error temporal** ‚Üí Retry autom√°tico + fallback
4. **Timeout** ‚Üí Mensaje de error + respuesta b√°sica

---

## üêõ **TROUBLESHOOTING**

### **LocalAI no inicia**
```bash
# Verificar Docker
docker --version

# Ver logs de error
docker logs agora-localai

# Reiniciar servicio
docker restart agora-localai

# Si falla, recrear:
docker stop agora-localai
docker rm agora-localai
.\install-agora-ai.bat
```

### **IA aparece offline**
1. **Verificar URL**: http://localhost:8080/health
2. **Firewall**: Permitir puerto 8080
3. **Antivirus**: Excluir Docker y LocalAI
4. **Puerto ocupado**: Cambiar en docker run -p 8081:8080

### **Respuestas lentas**
```yaml
# Optimizaciones en localai-models/*.yaml:
parameters:
  threads: 8        # M√°s threads si tienes CPU potente
  max_tokens: 100   # Menos tokens = m√°s r√°pido
  temperature: 0.3  # Menos creatividad = m√°s r√°pido
```

### **Modelos no descargan**
1. **Conexi√≥n internet** lenta/inestable
2. **Espacio disco**: Necesitas ~10GB libres  
3. **Descarga manual**:
```bash
# Ir a: https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML
# Descargar: llama-2-7b-chat.q4_0.bin
# Mover a: Backend-Symfony/localai-models/
```

---

## üìà **ROADMAP FUTURO**

### **Pr√≥ximas Mejoras**
- [ ] **WebSockets**: Chat en tiempo real
- [ ] **M√∫ltiples usuarios**: IA conversacional grupal  
- [ ] **Memoria persistente**: Conversaciones guardadas
- [ ] **Embeddings**: B√∫squeda sem√°ntica en archivos
- [ ] **Voice IA**: Texto-a-voz y voz-a-texto
- [ ] **Modelos especializados**: Medicina, Legal, etc.

### **Integraciones Avanzadas**
- [ ] **RAG System**: IA con conocimiento espec√≠fico del TFG
- [ ] **Code Assistant**: IA que ayuda programando  
- [ ] **Document AI**: An√°lisis autom√°tico de PDFs/docs
- [ ] **Image Generation**: DALL-E local con Stable Diffusion

---

## ‚ö° **COMANDOS R√ÅPIDOS**

```bash
# INICIAR TODO
.\install-agora-ai.bat

# VER ESTADO
docker ps | grep agora-localai

# VER LOGS  
docker logs -f agora-localai

# REINICIAR IA
docker restart agora-localai

# DETENER IA
docker stop agora-localai

# LIMPIAR TODO
docker stop agora-localai && docker rm agora-localai

# ACCESO DIRECTO
start http://localhost:8080/browse
```

---

## üéâ **¬°√âXITO! IA REAL EN TU TFG**

**Ya tienes:**
‚úÖ IA local privada (sin costos API)  
‚úÖ Bots inteligentes personalizables  
‚úÖ Interface profesional completa  
‚úÖ Fallbacks robustos  
‚úÖ Panel de control avanzado  
‚úÖ Documentaci√≥n completa  

**Resultado**: **Plataforma √Ågora con IA verdadera, lista para demostrar en el TFG.**

---

*üìã Documentaci√≥n generada autom√°ticamente - √Ågora AI System v1.0*